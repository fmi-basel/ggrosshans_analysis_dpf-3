configfile: "config.yaml"

################################################################################
### python modules
################################################################################

import os
import sys
import pandas as pd

################################################################################
### Custom functions
################################################################################

def get_samples():
    design_table = pd.read_csv(config["samples"], sep="\t", header=0)
    return list(design_table["sample"])

    # return ["dpf_3_delta_38_Hrs_Rev6_REPLICATE_B"]

def get_fq_1(wildcards):
    design_table = pd.read_csv(config["samples"], sep="\t", index_col="sample")
    return str(design_table.loc[wildcards.sample]["fq1"])

def get_fq_2(wildcards):
    design_table = pd.read_csv(config["samples"], sep="\t", index_col="sample")
    return str(design_table.loc[wildcards.sample]["fq2"])

################################################################################
### Finish
################################################################################

rule finish:
    input:
        # bai = expand(os.path.join(config["output_dir"], "{sample}", "STAR", "{sample}_Aligned.sortedByCoord.out.bam.bai"), sample=get_samples()),
        # pdf = expand(os.path.join(config["output_dir"], "summary", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf"), sample=get_samples()),
        multiqc_dir = os.path.join(config["output_dir"], "summary", "qc"),
        # index = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.salmon.idx"),
        # transcriptid2geneid = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.transcriptid2geneid.txt"),
        # salmon_filtered = expand(os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads", "quant.genes.filtered.tsv"), sample=get_samples())
        # salmon_genes_out = expand(os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads", "quant.genes.sf"), sample=get_samples()),
        # outdir = expand(os.path.join(config["output_dir"], "{sample}", "fastqc"), sample=get_samples()),
        # bai = expand(os.path.join(config["output_dir"], "{sample}", "STAR", "{sample}_Aligned.out.remove_pcr_duplicates.SortedByCoordinate.bam.bai"), sample=get_samples()),
        # htseq_counts_table = expand(os.path.join(config["output_dir"], "{sample}", "htseq", "count_genomic_alignment_htseq_unique_mappers.filtered.tsv"), sample=get_samples()),
        # multiqc_dir = os.path.join(config["output_dir"], "summary", "qc"),
        # pdf = os.path.join(config["output_dir"], "summary", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf"),
        # DE_htseq_unique_mappers = expand(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "htseq_unique_mappers", "final_table_FDR_low.tsv"),
        #                                  zip,
        #                                  experiment1 = [i[0]  for i in list(config["combinations"])],
        #                                  experiment2 = [i[1]  for i in list(config["combinations"])]),
        DE_salmon_quant_reads_with_transposon_annotation = expand(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table_with_transposons.tsv"),
                                                                  zip,
                                                                  experiment1 = [i[0]  for i in list(config["combinations"])],
                                                                  experiment2 = [i[1]  for i in list(config["combinations"])]),
        DE_salmon_quant_reads_transposons = expand(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads_transposons", "final_table_FDR_low.tsv"),
                                                                zip,
                                                                experiment1 = [i[0]  for i in list(config["combinations"])],
                                                                experiment2 = [i[1]  for i in list(config["combinations"])])
        
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
### Quality statistics (Part 1)
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

################################################################################
### Fastqc
################################################################################

rule fastqc:
    input:
        fq_1 = lambda wildcards: get_fq_1(wildcards)
    output:
        outdir = directory(os.path.join(config["output_dir"], "{sample}", "fastqc"))
    conda:
        "envs/fastqc.yaml"
    log:
        os.path.join(config["local_log"], "fastqc_{sample}.log")
    shell:
        "(mkdir -p {output.outdir}; \
        fastqc \
        --outdir {output.outdir} \
        {input.fq_1}) &> {log}"

################################################################################
### Trim 3p adapter
################################################################################

rule trim_3p_adapter_SE:
    input:
        reads = lambda wildcards: get_fq_1(wildcards),
    output:
        reads = os.path.join(config["output_dir"], "{sample}", "cutadapt", "trim_3p_adapter.fastq.gz"),
    params:
        adapter = "AGATCGGAAGAGCACACGTCTGAAC",
        error_rate = 0.1,
        minimum_length = 15,
        overlap = 3,
    log:
        os.path.join(config["local_log"], "trim_3p_adapter_SE_{sample}.log")
    threads:    6
    conda:  "envs/cutadapt.yaml"
    shell:
        "(cutadapt \
        --adapter {params.adapter} \
        --error-rate {params.error_rate} \
        --minimum-length {params.minimum_length} \
        --overlap {params.overlap} \
        --cores {threads} \
        {input.reads} | gzip > {output.reads}) &> {log}"

#################################################################################
### Index genome STAR
#################################################################################

rule index_genome_STAR:
    input:
        genome = config["genome"],
        annotation = config["gtf"]
    output:
        output = directory(os.path.join(config["output_dir"], "STAR_index"))
    params:
        outputdir = os.path.join(config["output_dir"],"STAR_index"),
        sjdbOverhang = config["sjdbOverhang"]
    threads:    40
    conda:
        "envs/STAR.yaml"
    log:
        os.path.join(config["local_log"], "index_genome_STAR.log")
    shell:
        "mkdir -p {output.output}; \
        chmod -R 777 {output.output}; \
        (STAR --runMode genomeGenerate \
        --sjdbOverhang {params.sjdbOverhang} \
        --genomeDir {params.outputdir} \
        --genomeFastaFiles {input.genome} \
        --runThreadN {threads} \
        --sjdbGTFfile {input.annotation}) &> {log}"

#################################################################################
### Align reads STAR
#################################################################################

rule align_reads_STAR:
    input:
        index = os.path.join(config["output_dir"], "STAR_index"),
        gtf = config["gtf"],
        reads = os.path.join(config["output_dir"], "{sample}", "cutadapt", "trim_3p_adapter.fastq.gz"),
    output:
        bam = os.path.join(config["output_dir"], "{sample}", "STAR", "{sample}_Aligned.sortedByCoord.out.bam"),
    params:
        outFileNamePrefix = os.path.join(config["output_dir"], "{sample}", "STAR", "{sample}_"),
        outputdir = os.path.join(config["output_dir"], "{sample}", "STAR"),
        outFilterMultimapNmax = 100,
        winAnchorMultimapNmax = 200
    log:
        os.path.join(config["local_log"],"align_reads_STAR_{sample}.log")
    threads:    20
    conda:
        "envs/STAR.yaml"
    shell:
        "(mkdir -p {params.outputdir}; \
        STAR --runMode alignReads \
        --twopassMode Basic \
        --runThreadN {threads} \
        --genomeDir {input.index} \
        --sjdbGTFfile {input.gtf} \
        --readFilesIn {input.reads} \
        --readFilesCommand zcat \
        --outFileNamePrefix {params.outFileNamePrefix} \
        --outSAMtype BAM SortedByCoordinate \
        --outFilterMultimapNmax {params.outFilterMultimapNmax} \
        --winAnchorMultimapNmax {params.winAnchorMultimapNmax}) &> {log}"

################################################################################
### Index alignment file
################################################################################

rule samtools_index_genomic_alignment:
    input:
        bam = os.path.join(config["output_dir"], "{sample}", "STAR", "{sample}_Aligned.sortedByCoord.out.bam")
    output:
        bai = os.path.join(config["output_dir"], "{sample}", "STAR", "{sample}_Aligned.sortedByCoord.out.bam.bai")
    log:
        os.path.join(config["local_log"],"samtools_index_genomic_alignment_{sample}.log")
    threads:    1
    conda:
        "envs/samtools.yaml"
    shell:
        "(samtools index {input.bam} > {output.bai}) &> {log}"

################################################################################
### Generate alfa genome index
################################################################################

rule alfa_genome_index:
    input:
        gtf = config["gtf"],
        chr_len = config["genome_size"]
    output:
        alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index"),
        alfa_index_unstranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.unstranded.ALFA_index")
    params:
        genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index")
    log:
        os.path.join(config["local_log"], "alfa_genome_index.log")
    threads:    8
    conda:
        "envs/alfa.yaml"
    shell:
        "(alfa \
        -a {input.gtf} \
        -g {params.genome_index_basename} \
        --chr_len {input.chr_len} \
        -p {threads}) &> {log}"

################################################################################
### Determine alignment statistics
################################################################################

rule alfa_aligment_statistics:
    input:
        bam = expand(os.path.join(config["output_dir"], "{sample1}", "STAR", "{sample1}_Aligned.sortedByCoord.out.bam"), sample1=get_samples()),
        bai = expand(os.path.join(config["output_dir"], "{sample1}", "STAR", "{sample1}_Aligned.sortedByCoord.out.bam.bai"), sample1=get_samples()),
        alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index"),
    output:
        pdf = os.path.join(config["output_dir"], "summary", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf")
    params:
        genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index"),
        output_prefix = "alfa_aligment_statistics",
        output_dir = os.path.join(config["output_dir"], "summary", "alfa_aligment_statistics"),
        bam_and_sample_name = expand(str(os.path.join(config["output_dir"], "{sample1}", "STAR", "{sample1}_Aligned.sortedByCoord.out.bam ")) +str("{sample1}"), sample1=get_samples()),
        strandness = "forward"
    log:
        os.path.join(config["local_log"],"alfa_aligment_statistics.log")
    threads:    8
    conda:
        "envs/alfa.yaml"
    shell:
        "(mkdir -p {params.output_dir}; \
        alfa \
        -g {params.genome_index_basename} \
        --bam {params.bam_and_sample_name} \
        -d 2 \
        --keep_ambiguous \
        --processors {threads} \
        --strandness {params.strandness} \
        --pdf {params.output_prefix} \
        --temp_dir {params.output_dir} \
        -o {params.output_dir}; \
        ) &> {log}"

################################################################################
### Multiqc
################################################################################

rule multiqc:
    input:
        fastqc = expand(os.path.join(config["output_dir"], "{sample}", "fastqc"), sample=get_samples()),
        pdf = os.path.join(config["output_dir"], "summary", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf")
    output:
        multiqc_dir = directory(os.path.join(config["output_dir"], "summary", "qc"))
    log:
        os.path.join(config["local_log"], "multiqc_fastqc.log")
    conda:
        "envs/multiqc.yaml"
    shell:
        "(multiqc --outdir {output.multiqc_dir} results logs) &> {log}"


################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
### Create custom annotation
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

################################################################################
### Concatenate normal transcripts and transcripts annotated as
### transposons transcripts
### ALL (before filtering)
################################################################################

rule concatenate_canonical_and_transposon_transcripts_all:
    input:
        gtf = config["gtf"],
        gtf_transposon_transcripts = config["gtf_transposon_transcripts"]
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.canonical_and_transposon_transcripts.gtf")
    log:
        os.path.join(config["local_log"], "concatenate_canonical_and_transposon_transcripts_all.log")
    shell:
        "(cat {input.gtf} {input.gtf_transposon_transcripts} > {output.gtf}) &> {log}"

################################################################################
### Filter small RNAs from annotation file
################################################################################

rule filter_RNAs_from_gtf:
    input:
        gtf = config["gtf"]
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.gtf")
    log:
        os.path.join(config["local_log"], "filter_RNAs_from_gtf.log")
    shell:
        "(grep -P \"\texon\t\" {input.gtf} | \
        grep -P -v \"miRNA|piRNA|pre_miRNA|rRNA|rRNA_pseudogene|snRNA|snoRNA|tRNA|tRNA_pseudogene\" | \
        grep -P -v \"^MtDNA\" > {output.gtf}) &> {log}"

################################################################################
### Concatenate normal transcripts and transcripts annotated as
### transposons transcripts
################################################################################

rule concatenate_canonical_and_transposon_transcripts:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.gtf"),
        gtf_transposon_transcripts = config["gtf_transposon_transcripts"]
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.gtf")
    log:
        os.path.join(config["local_log"], "concatenate_canonical_and_transposon_transcripts.log")
    shell:
        "(cat \
        {input.gtf} \
        <(grep -P \"\texon\t\" {input.gtf_transposon_transcripts}) \
        > {output.gtf}) &> {log}"

################################################################################
### Extract canonical and transposon transcripts sequences
################################################################################

rule extract_canonical_and_transposon_transcripts_sequences:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.gtf"),
        genome = config["genome"]
    output:
        seq = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.fa")
    conda:
        "envs/cufflinks.yaml"
    log:
        os.path.join(config["local_log"], "extract_miRNA_sequences.log")
    shell:
        "(gffread \
        {input.gtf} \
        -g {input.genome} \
        -w {output.seq} \
        ) &> {log}"

################################################################################
### Index canonical and transposon transcripts with salmon
################################################################################

rule index_canonical_and_transposon_transcripts_salmon:
    input:
        transcripts = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.fa")
    output:
        index = directory(os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.salmon.idx"))
    params:
        kmer = 21
    threads:    20
    conda:
        "envs/salmon.yaml"
    log:
        os.path.join(config["local_log"], "index_canonical_and_transposon_transcripts_salmon.log")
    shell:
        "(salmon index \
        -t {input.transcripts} \
        -i {output.index} \
        -k {params.kmer}) &> {log}"

################################################################################
### canonical and transposon transcripts transcript id to gene id
################################################################################

rule transcript_id_to_gene_id_canonical_and_transposon_transcripts:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.gtf"),
    output:
        transcriptid2geneid = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.transcriptid2geneid.txt")
    log:
        os.path.join(config["local_log"], "transcript_id_to_gene_id_canonical_and_transposon_transcripts.log")
    shell:
        "(cut -f 9 {input.gtf} | \
        cut -f 1-2 -d \";\" | \
        sed \'s/gene_id \"//\' | \
        sed \'s/\"; transcript_id \"/ /\' | \
        sed \'s/\\\"//\' | \
        sort -u | \
        awk \'{{print $2 \" \" $1}}\' \
        > {output.transcriptid2geneid} \
        ) &> {log}"
        
################################################################################
### Index transposon with salmon
################################################################################

rule index_transposons_salmon:
    input:
        transcripts = config["transposons"]
    output:
        index = directory(os.path.join(config["output_dir"], "annotation", "transposons.salmon.idx"))
    params:
        kmer = 21
    threads:    20
    conda:
        "envs/salmon.yaml"
    log:
        os.path.join(config["local_log"], "index_transposons_salmon.log")
    shell:
        "(salmon index \
        -t {input.transcripts} \
        -i {output.index} \
        -k {params.kmer}) &> {log}"
        
################################################################################
### transposons to transposons family
################################################################################

rule transposons_to_transposons_family:
    input:
        gff = config["gff_transposons"]
    output:
        transposons2transposons_family = os.path.join(config["output_dir"], "annotation", "annotation.transposons_to_transposons_family.txt")
    log:
        os.path.join(config["local_log"], "transposons_to_transposons_family.log")
    shell:
        "(cut -f 9 {input.gff} | \
        grep Family | grep Name | \
        cut -f 2,3 -d \";\" | \
        sed \'s/Name=//\' | \
        sed \'s/;Family=/ /\' | \
        sort -u \
        > {output.transposons2transposons_family} \
        ) &> {log}"
        
        
################################################################################
### gff 2 bed for transposons (Transposon Elements)
################################################################################

rule gff_transposons_2_bed:
    input:
        gff = config["gff_transposons"],
        script = os.path.join(config["scripts"], "gff_transposons_2_bed.py")
    output:
        bed = os.path.join(config["output_dir"], "annotation", "c_elegans.PRJNA13758.WS270.annotations.WormBase_transposon.transposons.bed")
    log:
        os.path.join(config["local_log"], "gff_transposons_2_bed.log")
    conda:
        "envs/HTSeq_pandas_samtools_seaborn.yaml"        
    shell:
        "(python {input.script} \
        --gff {input.gff} \
        --bed {output.bed} \
        --verbose \
        ) &> {log}"

################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
### Quantify and DE salmon quant reads
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

################################################################################
### Salmon quantify based on reads
################################################################################

rule salmon_quant_reads:
    input:
        reads = os.path.join(config["output_dir"], "{sample}", "cutadapt", "trim_3p_adapter.fastq.gz"),
        index = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.salmon.idx"),
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.transcriptid2geneid.txt")
    output:
        salmon_out = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads", "quant.sf"),
        salmon_genes_out = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads", "quant.genes.sf"),
    params:
        libType = "A",
        salmon_dir = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads")
    log:
        os.path.join(config["local_log"], "salmon_quant_reads_{sample}.log")
    threads:    12
    conda:
        "envs/salmon.yaml"
    shell:
        "(salmon quant \
        --libType {params.libType} \
        --seqBias \
        --validateMappings \
        --threads {threads} \
        --writeUnmappedNames \
        --index {input.index} \
        --geneMap {input.gtf} \
        --unmatedReads {input.reads} \
        -o {params.salmon_dir}) &> {log}"

################################################################################
### Filter salmon and round reads
################################################################################

rule filter_salmon_quant_reads:
    input:
        salmon_genes_out = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads", "quant.genes.sf"),
    output:
        salmon_filtered = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads", "quant.genes.filtered.tsv")
    log:
        os.path.join(config["local_log"], "filter_salmon_quant_reads_{sample}.log")
    run:
        df = pd.read_csv(input.salmon_genes_out, header=0, sep="\t")
        df = df[["Name", "NumReads"]].copy()
        df.columns = ["Name", "counts"]
        df["counts"] = df["counts"].round()
        df["counts"] = df["counts"].astype(int)
        df.set_index("Name", inplace=True)
        df.to_csv(output.salmon_filtered, header=True, sep="\t", index=True)

################################################################################
### Input preparation for edgeR (salmon quant reads)
################################################################################

rule edgeR_prepare_pairs_salmon_quant_reads:
    input:
        counts1 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample1}", "salmon", "quant_reads", "quant.genes.filtered.tsv"), sample1=config["experiment_samples"][wildcards.experiment1]),
        counts2 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample2}", "salmon", "quant_reads", "quant.genes.filtered.tsv"), sample2=config["experiment_samples"][wildcards.experiment2]),
        script = os.path.join(config["scripts"], "edger_prepare_files.py")
    output:
        counts = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads", "counts.table"),
        conditions = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads", "conditions")
    params:
        output_dir = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads"),
        condition1_name = "{experiment1}",
        condition2_name = "{experiment2}"
    log:
        os.path.join(config["local_log"], "edgeR_prepare_pairs_salmon_quant_reads__{experiment1}__{experiment2}.log")
    threads:    1
	shell:
		"(mkdir -p {params.output_dir}; \
		python {input.script} \
		--input_condition1 '{input.counts1}' \
		--condition1_name {params.condition1_name} \
		--input_condition2 '{input.counts2}' \
		--condition2_name {params.condition2_name} \
		--outfile_counts {output.counts} \
		--outfile_conditions {output.conditions}) &> {log}"

################################################################################
### Differential expression between conditions (salmon)
################################################################################

rule edgeR_differential_salmon_quant_reads:
    input:
        counts = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads", "counts.table"),
        conditions = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads", "conditions"),
        gtf = os.path.join(config["output_dir"], "annotation", "annotation.canonical_and_transposon_transcripts.gtf"),
        script = os.path.join(config["scripts"], "DE.R")
    output:
        table_FDR_low_tsv = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table_FDR_low.tsv"),
        table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table.tsv")
    params:
        output_dir = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads"),
    conda:
        "envs/DE.yaml"
    log:
        os.path.join(config["local_log"], "edgeR_differential_salmon_quant_reads__{experiment1}__{experiment2}.log")
    threads:    1
    shell:
        "(mkdir -p {params.output_dir}; \
        Rscript {input.script} \
        --conditions {input.conditions} \
        --counts {input.counts} \
        --gtf {input.gtf} \
        --outfolder {params.output_dir}) &> {log}"
        
################################################################################
### edgeR_differential_salmon_quant_to_bed
################################################################################

rule edgeR_differential_salmon_quant_to_bed:
    input:
        table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table.tsv")
    output:
        table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table.bed")
    threads:    1
    log:
        os.path.join(config["local_log"], "edgeR_differential_salmon_quant_to_bed__{experiment1}__{experiment2}.log")
    run:
        de = pd.read_csv(input.table_all, header=0, sep="\t")
        de["score"] = 0
        df_bed = de[["chromosome", "start", "end", "id", "score", "strand"]].copy()
        df_bed["start"] = df_bed["start"] - 1
        df_bed.to_csv(output.table_all, header=None, index=False, sep="\t")
        
################################################################################
### edgeR_differential_salmon_quant_annotate_transposons
################################################################################

rule edgeR_differential_salmon_quant_annotate_transposons:
    input:
        table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table.bed"),
        bed_transposons = os.path.join(config["output_dir"], "annotation", "c_elegans.PRJNA13758.WS270.annotations.WormBase_transposon.transposons.bed")
    output:
        table_all_intersect = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table_intersect.bed")
    threads:    1
    conda:
        "envs/bedtools.yaml"
    log:
        os.path.join(config["local_log"], "edgeR_differential_salmon_quant_annotate_transposons__{experiment1}__{experiment2}.log")
    shell:
        "(bedtools intersect \
        -a {input.table_all} \
        -b {input.bed_transposons} \
        -wa \
        -wb \
        -f 0.5 \
        > {output.table_all_intersect} \
        ) &> {log}"

################################################################################
### edgeR_differential_salmon_quant_annotate_transposons
################################################################################

rule edgeR_differential_salmon_quant_update_DE_table:
    input:
        table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table.tsv"),
        table_all_intersect = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table_intersect.bed")
    output:
        final_table_with_transposons = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads", "final_table_with_transposons.tsv"),
    threads:    1
    log:
        os.path.join(config["local_log"], "edgeR_differential_salmon_quant_update_DE_table__{experiment1}__{experiment2}.log")
    run:
        # read in file intersection file
        table_all_intersect = pd.read_csv(input.table_all_intersect, header = None, sep="\t")
        # add column names
        table_all_intersect.columns = ["gene_chrom", "gene_start", "gene_end", "id", "gene_score", "gene_strand", "transposon_chrom", "transposon_start", "transposon_end", "transposon_and_family", "transposon_score", "transposon_strand"]
        # convert starts to 1-based
        table_all_intersect["gene_start"] = table_all_intersect["gene_start"] + 1
        table_all_intersect["transposon_start"] = table_all_intersect["transposon_start"] + 1
        # split transposon_and_family to two columns
        table_all_intersect[["transposon", "transposon_family"]] =  table_all_intersect["transposon_and_family"].str.split("$", expand=True)
        # select only useful columns
        table_all_intersect = table_all_intersect[["id", "transposon", "transposon_family", "transposon_chrom", "transposon_start", "transposon_end", "transposon_strand"]]
        
        # read in DE table from edgeR
        table_all = pd.read_csv(input.table_all, header=0, sep="\t")
        
        # merge dataframes
        df_all = pd.merge(table_all, table_all_intersect, on="id", how="left")
        
        # write file
        df_all.to_csv(output.final_table_with_transposons, header=True, index=False, sep="\t")
        
        
        
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
### Quantify and DE transposons
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

###############################################################################
## Salmon quantify transposons based on reads
###############################################################################

rule salmon_quant_reads_transposons:
    input:
        reads = os.path.join(config["output_dir"], "{sample}", "cutadapt", "trim_3p_adapter.fastq.gz"),
        index = os.path.join(config["output_dir"], "annotation", "transposons.salmon.idx"),
        geneMap = os.path.join(config["output_dir"], "annotation", "annotation.transposons_to_transposons_family.txt")
    output:
        salmon_out = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads_transposons", "quant.sf"),
        salmon_genes_out = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads_transposons", "quant.genes.sf"),
    params:
        libType = "A",
        salmon_dir = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads_transposons")
    log:
        os.path.join(config["local_log"], "salmon_quant_reads_transposons_by_family_{sample}.log")
    threads:    12
    conda:
        "envs/salmon.yaml"
    shell:
        "(salmon quant \
        --libType {params.libType} \
        --seqBias \
        --validateMappings \
        --threads {threads} \
        --writeUnmappedNames \
        --index {input.index} \
        --unmatedReads {input.reads} \
        --geneMap {input.geneMap} \
        -o {params.salmon_dir}) &> {log}"
        
################################################################################
### Filter salmon transposons quantification and round reads
################################################################################

rule filter_salmon_quant_reads_transposons:
    input:
        salmon_genes_out = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads_transposons", "quant.genes.sf"),
    output:
        salmon_filtered = os.path.join(config["output_dir"], "{sample}", "salmon", "quant_reads_transposons", "quant.genes.filtered.tsv"),
    log:
        os.path.join(config["local_log"], "filter_salmon_quant_reads_transposons_{sample}.log")
    run:
        df = pd.read_csv(input.salmon_genes_out, header=0, sep="\t")
        df = df[["Name", "NumReads"]].copy()
        df.columns = ["Name", "counts"]
        df["counts"] = df["counts"].round()
        df["counts"] = df["counts"].astype(int)
        df.set_index("Name", inplace=True)
        df.to_csv(output.salmon_filtered, header=True, sep="\t", index=True)
        
################################################################################
### Input preparation for edgeR (salmon quant reads)
################################################################################

rule edgeR_prepare_pairs_salmon_quant_reads_transposons:
    input:
        counts1 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample1}", "salmon", "quant_reads_transposons", "quant.genes.filtered.tsv"), sample1=config["experiment_samples"][wildcards.experiment1]),
        counts2 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample2}", "salmon", "quant_reads_transposons", "quant.genes.filtered.tsv"), sample2=config["experiment_samples"][wildcards.experiment2]),
        script = os.path.join(config["scripts"], "edger_prepare_files.py")
    output:
        counts = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads_transposons", "counts.table"),
        conditions = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads_transposons", "conditions")
    params:
        output_dir = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads_transposons"),
        condition1_name = "{experiment1}",
        condition2_name = "{experiment2}"
    log:
        os.path.join(config["local_log"], "edgeR_prepare_pairs_salmon_quant_reads_transposons__{experiment1}__{experiment2}.log")
    threads:    1
	shell:
		"(mkdir -p {params.output_dir}; \
		python {input.script} \
		--input_condition1 '{input.counts1}' \
		--condition1_name {params.condition1_name} \
		--input_condition2 '{input.counts2}' \
		--condition2_name {params.condition2_name} \
		--outfile_counts {output.counts} \
		--outfile_conditions {output.conditions}) &> {log}"
  
################################################################################
### Differential expression between conditions (salmon)
################################################################################

rule edgeR_differential_salmon_quant_reads_transposons:
    input:
        counts = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads_transposons", "counts.table"),
        conditions = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs", "salmon_quant_reads_transposons", "conditions"),
        script = os.path.join(config["scripts"], "DE_simple.R")
    output:
        table_FDR_low_tsv = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads_transposons", "final_table_FDR_low.tsv"),
        table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads_transposons", "final_table.tsv")
    params:
        output_dir = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "salmon_quant_reads_transposons"),
    conda:
        "envs/DE.yaml"
    log:
        os.path.join(config["local_log"], "edgeR_differential_salmon_quant_reads_transposons__{experiment1}__{experiment2}.log")
    threads:    1
    shell:
        "(mkdir -p {params.output_dir}; \
        Rscript {input.script} \
        --conditions {input.conditions} \
        --counts {input.counts} \
        --outfolder {params.output_dir}) &> {log}"