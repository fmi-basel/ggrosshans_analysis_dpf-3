configfile: "config.yaml"

################################################################################
### python modules
################################################################################

import os
import sys
import pandas as pd
import matplotlib.pyplot as plt
from functools import reduce

################################################################################
### Custom functions
################################################################################

def get_samples():
    design_table = pd.read_csv(config["samples"], sep="\t", header=0)
    return list(design_table["sample"])

def get_fq_1(wildcards):
    design_table = pd.read_csv(config["samples"], sep="\t", index_col="sample")
    return str(design_table.loc[wildcards.sample]["fq1"])

def get_fq_2(wildcards):
    design_table = pd.read_csv(config["samples"], sep="\t", index_col="sample")
    return str(design_table.loc[wildcards.sample]["fq2"])

################################################################################
### Finish
################################################################################

rule finish:
    input:
        #out_potential_umis = expand(os.path.join(config["output_dir"], "{sample}", "potential_umis", "{kmer_len}", "counts.tsv"), sample=get_samples(), kmer_len=config["kmer_len"]),
        fastqc = expand(os.path.join(config["output_dir"], "{sample}", "fastqc"), sample=get_samples()),
        out_freq = expand(os.path.join(config["output_dir"], "{sample}", "frequency_for_UMI_detection", "frequency.tsv"), sample=get_samples()),
        pdf = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf"),
        pdf_other = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_filter", "alfa_aligment_statistics_filter.Biotypes.pdf"),
        stats = os.path.join(config["output_dir"], "summary", "stats", "stats.tsv"),
        #fastqc_filtered = expand(os.path.join(config["output_dir"], "{sample}", "fastqc_filtered"), sample=get_samples()),
        # prepare_pairs_22G = expand(os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "final_table_FDR_low.tsv"),
        #                            zip,
        #                            experiment1 = [i[0]  for i in list(config["combinations"])],
        #                            experiment2 = [i[1]  for i in list(config["combinations"])]),
        prepare_pairs_all = expand(os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "DE_edgeR", "final_table_FDR_low.tsv"),
                                    zip,
                                    experiment1 = [i[0]  for i in list(config["combinations"])],
                                    experiment2 = [i[1]  for i in list(config["combinations"])]),
        htseq_focus = expand(os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "counts22G.tsv"),
                             zip,
                             experiment1 = [i[0]  for i in list(config["combinations_focus"])],
                             experiment2 = [i[1]  for i in list(config["combinations_focus"])])
        # multiqc_dir = directory(os.path.join(config["output_dir"], "summary", "qc"))

################################################################################
### Generate alfa genome index
################################################################################

rule alfa_genome_index:
    input:
        gtf = config["gtf"],
        chr_len = config["genome_size"]
    output:
        alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index"),
        alfa_index_unstranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.unstranded.ALFA_index")
    params:
        genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index")
    log:
        os.path.join(config["local_log"], "alfa_genome_index.log")
    threads:    8
    conda:
        "envs/alfa.yaml"
    shell:
        "(alfa \
        -a {input.gtf} \
        -g {params.genome_index_basename} \
        --chr_len {input.chr_len} \
        -p {threads}) &> {log}"

################################################################################
### Fastqc
################################################################################

rule fastqc:
    input:
        fq_1 = lambda wildcards: get_fq_1(wildcards)
    output:
        outdir = directory(os.path.join(config["output_dir"], "{sample}", "fastqc"))
    conda:
        "envs/fastqc.yaml"
    log:
        os.path.join(config["local_log"], "fastqc_{sample}.log")
    shell:
        "(mkdir -p {output.outdir}; \
        fastqc \
        --outdir {output.outdir} \
        {input.fq_1}) &> {log}"

################################################################################
### detect potential umis
################################################################################

rule detect_umis:
    input:
        fq_1 = lambda wildcards: get_fq_1(wildcards),
        script = os.path.join(config["scripts"], "detect_umis_small_RNAs.py"),
    output:
        out = os.path.join(config["output_dir"], "{sample}", "potential_umis", "{kmer_len}", "counts.tsv")
    params:
        adapter = config["adapter"],
        extend_after_adapter = "{kmer_len}",
    conda:
        "envs/pandas_biopython.yaml"
    log:
        os.path.join(config["local_log"], "detect_umis_{sample}_{kmer_len}.log")
    shell:
        "(python {input.script} \
        --fastq <(zcat {input.fq_1}) \
        --adapter {params.adapter} \
        --extend-after-adapter {params.extend_after_adapter} \
        --out {output.out} \
        --verbose) &> {log}"

rule calculate_frequency_for_UMI_detection:
    input:
        fq_1 = lambda wildcards: get_fq_1(wildcards),
        script = os.path.join(config["scripts"], "calculate_frequency_for_UMI_detection.py"),
    output:
        out = os.path.join(config["output_dir"], "{sample}", "frequency_for_UMI_detection", "frequency.tsv")
    params:
        adapter = config["adapter"]
    conda:
        "envs/pandas_biopython_numpy.yaml"
    log:
        os.path.join(config["local_log"], "calculate_frequency_for_UMI_detection_{sample}.log")
    shell:
        "(python {input.script} \
        --fastq <(zcat {input.fq_1}) \
        --adapter {params.adapter} \
        --out {output.out} \
        --verbose \
        ) &> {log}"

rule separate_reads_based_on_adapter_and_umi:
    input:
        fq_1 = lambda wildcards: get_fq_1(wildcards),
        script = os.path.join(config["scripts"], "separate_reads_based_on_adapter_and_umi.py"),
    output: 
        fq =  os.path.join(config["output_dir"], "{sample}", "split_reads", "adapter_and_umi_present.fastq.gz")
    params:
        out = os.path.join(config["output_dir"], "{sample}", "split_reads"),
        adapter = config["adapter"],
        umi_length = config["umi_length"]
    conda:
        "envs/pandas_biopython_numpy.yaml"
    log:
        os.path.join(config["local_log"], "separate_reads_based_on_adapter_and_umi_{sample}.log")
    shell:
        "(python {input.script} \
        --fastq <(zcat {input.fq_1}) \
        --adapter {params.adapter} \
        --umi-length {params.umi_length} \
        --out {params.out} \
        --attach-umis-to-header \
        --compress \
        --verbose \
        ) &> {log}"

################################################################################
### Trim 3p adapter
################################################################################

rule trim_3p_adapter_SE:
    input:
        reads =  os.path.join(config["output_dir"], "{sample}", "split_reads", "adapter_and_umi_present.fastq.gz")
    output:
        reads = os.path.join(config["output_dir"], "{sample}", "trim_3p_adapter", "trim_3p_adapter.fastq.gz")
    params:
        adapter = config["adapter"],
        error_rate = 0.1,
        minimum_length = 15,
        overlap = 3,
    log:
        os.path.join(config["local_log"], "trim_3p_adapter_SE_{sample}.log")
    threads:    6
    conda:  "envs/cutadapt.yaml"
    shell:
        "(cutadapt \
        --adapter {params.adapter} \
        --error-rate {params.error_rate} \
        --minimum-length {params.minimum_length} \
        --overlap {params.overlap} \
        --cores {threads} \
        {input.reads} | gzip > {output.reads}) &> {log}"

################################################################################
### Filter low quality reads
################################################################################

rule filter_low_quality_reads:
    input:
        reads = os.path.join(config["output_dir"], "{sample}", "trim_3p_adapter", "trim_3p_adapter.fastq.gz")
    output:
        reads = os.path.join(config["output_dir"], "{sample}", "filter_low_quality_reads", "filter_quality.fastq.gz")
    params:
        q = "20",
        p = "100",
        Q = "33",
        z = "-z"
    log:
        os.path.join(config["local_log"], "filter_low_quality_reads_{sample}.log")
    threads:    2
    conda:  "envs/fastx_toolkit.yaml"
    shell:
        "(fastq_quality_filter \
        -q {params.q} \
        -p {params.p} \
        -Q {params.Q} \
        {params.z} \
        -i <(zcat {input.reads}) \
        -o {output.reads}) &> {log}"

################################################################################
### Collapse reads based on UMI
################################################################################

rule collapse_reads_based_on_umi:
    input:
        reads = os.path.join(config["output_dir"], "{sample}", "filter_low_quality_reads", "filter_quality.fastq.gz"), 
        script = os.path.join(config["scripts"], "collapse_reads_based_on_umi.py")
    output:
        reads = os.path.join(config["output_dir"], "{sample}", "collapse_reads", "collapsed.fastq.gz"),
    params:
        out = os.path.join(config["output_dir"], "{sample}", "collapse_reads")
    log:
        os.path.join(config["local_log"], "collapse_reads_based_on_umi_{sample}.log")
    threads:    2
    conda:
        "envs/pandas_biopython_numpy.yaml"
    shell:
        "(python {input.script} \
        --fastq <(zcat {input.reads}) \
        --out {params.out} \
        --compress \
        --verbose \
        ) &> {log}"

# ################################################################################
# ### Fastqc_filtered
# ################################################################################

# rule fastqc_filtered:
#     input:
#         reads = os.path.join(config["output_dir"], "{sample}", "filter_low_quality_reads", "filter_quality.fastq.gz"), 
#     output:
#         outdir = directory(os.path.join(config["output_dir"], "{sample}", "fastqc_filtered"))
#     conda:
#         "envs/fastqc.yaml"
#     log:
#         os.path.join(config["local_log"], "fastqc_filtered_{sample}.log")
#     shell:
#         "(mkdir -p {output.outdir}; \
#         fastqc \
#         --outdir {output.outdir} \
#         {input.reads}) &> {log}"

################################################################################
### bowtie align
################################################################################

rule bowtie_align:
    input:
        reads = os.path.join(config["output_dir"], "{sample}", "collapse_reads", "collapsed.fastq.gz"),
        bowtie_index = config["bowtie_index"]
    output:
        bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.bam"),
        bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.bam.bai")
    params:
        index_prefix = config["bowtie_index"] + "/bowtie"
    threads:   8
    conda:
        "envs/bowtie.yaml"
    log:
        os.path.join(config["local_log"],"bowtie_align_{sample}.log")
    shell:
        "(bowtie \
        -v 0 \
        --all \
        --best \
        --strata \
        --sam \
        --fr \
        --threads {threads} \
        {params.index_prefix} \
        <(zcat {input.reads}) \
        | samtools view -bS - \
        | samtools sort \
        -m 10G \
        --threads {threads} \
        --output-fmt BAM - \
        -o {output.bam}; \
        samtools index -@ {threads} {output.bam} {output.bai}; \
        ) &> {log}"

################################################################################
### Determine alignment statistics
################################################################################

rule alfa_aligment_statistics:
    input:
        bam = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.bam"), sample1=get_samples()),
        bai = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.bam.bai"), sample1=get_samples()),
        alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index"),
    output:
        pdf = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf")
    params:
        genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index"),
        output_prefix = "alfa_aligment_statistics",
        output_dir = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics"),
        bam_and_sample_name = expand(str(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.bam ")) +str("{sample1}"), sample1=get_samples()),
        strandness = "forward"
    log:
        os.path.join(config["local_log"],"alfa_aligment_statistics.log")
    threads:    8
    conda:
        "envs/alfa.yaml"
    shell:
        "(mkdir -p {params.output_dir}; \
        alfa \
        -g {params.genome_index_basename} \
        --bam {params.bam_and_sample_name} \
        -d 2 \
        --keep_ambiguous \
        --processors {threads} \
        --strandness {params.strandness} \
        --pdf {params.output_prefix} \
        --temp_dir {params.output_dir} \
        -o {params.output_dir}; \
        ) &> {log}"

################################################################################
### Filter small RNAs that we are not interested in
### (rRNA rRNA_pseudogene tRNA tRNA_pseudogene)
################################################################################

rule filter_RNAs:
    input:
        bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.bam"),
        bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.bam.bai"),
        gtf = config["gtf"],
        script = os.path.join(config["scripts"], "filter_RNAs.py"),
    output:
        bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam"),
        bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam.bai")
    params:
        filter_RNAs = config["filter_RNAs"],
        filter_chromosomes = config["filter_chromosomes"]
    log:
        os.path.join(config["local_log"],"filter_RNAs_{sample}.log")
    threads:    2
    conda:
        "envs/HTSeq_pandas_samtools_seaborn.yaml"
    shell:
        "(python {input.script} \
        --gtf {input.gtf} \
        --bam {input.bam} \
        --filter_RNAs {params.filter_RNAs} \
        --filter_chromosomes {params.filter_chromosomes} \
        --bam_out {output.bam} \
        --verbose; \
        samtools index -@ {threads} {output.bam} {output.bai};)"

################################################################################
### summarize number of reads per step
################################################################################

rule summarize_number_of_reads:
    input:
        input_reads = lambda wildcards: get_fq_1(wildcards),
        adapter_and_umi_present =  os.path.join(config["output_dir"], "{sample}", "split_reads", "adapter_and_umi_present.fastq.gz"),
        trim_3p_adapter = os.path.join(config["output_dir"], "{sample}", "trim_3p_adapter", "trim_3p_adapter.fastq.gz"),
        filter_quality = os.path.join(config["output_dir"], "{sample}", "filter_low_quality_reads", "filter_quality.fastq.gz"),
        collapsed = os.path.join(config["output_dir"], "{sample}", "collapse_reads", "collapsed.fastq.gz"),
        bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.bam"),
        bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.bam.bai"),
        bam_filtered = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam"),
        bai_filtered = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam.bai")
    output:
        stats = os.path.join(config["output_dir"], "{sample}", "stats", "stats.txt")
    log:
        os.path.join(config["local_log"],"summarize_number_of_reads_{sample}.log")
    threads:    2
    conda:
        "envs/HTSeq_pandas_samtools_seaborn.yaml"
    shell:
        "(\
        paste <(echo 'input_reads') <(zcat {input.input_reads} | grep -P '^@' | wc -l) >> {output.stats}; \
        paste <(echo 'adapter_and_umi_present') <(zcat {input.adapter_and_umi_present} | grep -P '^@' | wc -l) >> {output.stats}; \
        paste <(echo 'trim_3p_adapter') <(zcat {input.trim_3p_adapter} | grep -P '^@' | wc -l) >> {output.stats}; \
        paste <(echo 'filter_quality') <(zcat {input.filter_quality} | grep -P '^@' | wc -l) >> {output.stats}; \
        paste <(echo 'collapsed') <(zcat {input.collapsed} | grep -P '^@' | wc -l) >> {output.stats}; \
        paste <(echo 'mapped_reads') <(samtools view {input.bam} | awk '{{if (($2==0) || ($2==16) ) {{print($_)}}}}' | cut -f 1 | sort -u | wc -l) >> {output.stats}; \
        paste <(echo 'mapped_reads_filtered') <(samtools view {input.bam_filtered} | awk '{{if (($2==0) || ($2==16) ) {{print($_)}}}}' | cut -f 1 | sort -u | wc -l) >> {output.stats}; \
        ) 2> {log}"


################################################################################
### summarize number of reads per step
################################################################################

rule collapse_summarize_number_of_reads:
    input:
        stats = expand(os.path.join(config["output_dir"], "{sample}", "stats", "stats.txt"), sample=get_samples())
    output:
        stats = os.path.join(config["output_dir"], "summary", "stats", "stats.tsv"),
        steps_plot = os.path.join(config["output_dir"], "summary", "stats", "stats.pdf")
    params:
        sample_name = expand("{sample}", sample=get_samples())
    log:
        os.path.join(config["local_log"],"collapse_summarize_number_of_reads.log")
    threads:    1
    run:
        dfs = []
        for i in range(0, len(input.stats)):
            df = pd.read_csv(input.stats[i], header=None, sep="\t")
            sample_name = params.sample_name[i]
            df.columns = ["steps", sample_name]
            dfs.append(df)
        df_final = reduce(lambda left,right: pd.merge(left, right, on='steps', how="outer"), dfs)
        df_final.to_csv(output.stats, header=True, sep="\t", index=False)
        df_final.set_index("steps", inplace=True)
        df_final.T.plot.bar(figsize=(30,20)).figure.savefig(output.steps_plot)


################################################################################
### Determine alignment statistics after filtering reads
################################################################################

rule alfa_aligment_statistics_filter:
    input:
        bam = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.bam"), sample1=get_samples()),
        bai = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.bam.bai"), sample1=get_samples()),
        alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index")
    output:
        pdf = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_filter", "alfa_aligment_statistics_filter.Biotypes.pdf")
    params:
        genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index"),
        output_prefix = "alfa_aligment_statistics_filter",
        output_dir = os.path.abspath(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_filter")),
        bam_and_sample_name = expand(str(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.bam ")) +str("{sample1}"), sample1=get_samples()),
        strandness = "forward"
    log:
        os.path.join(config["local_log"],"alfa_aligment_statistics_filter.log")
    threads:    8
    conda:
        "envs/alfa.yaml"
    shell:
        "(mkdir -p {params.output_dir}; \
        alfa \
        -g {params.genome_index_basename} \
        --bam {params.bam_and_sample_name} \
        -d 2 \
        --keep_ambiguous \
        --processors {threads} \
        --strandness {params.strandness} \
        --pdf {params.output_prefix} \
        --temp_dir {params.output_dir} \
        -o {params.output_dir}; \
        ) &> {log}"

################################################################################
### count sequences
################################################################################

rule count_sequences:
    input:
        bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam"),
        bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam.bai"),
        script = os.path.join(config["scripts"], "count_sequences.py")
    output:
        counts = os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered", "counts.tsv")
    params:
        outdir = os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered")
    threads:    1
    conda:
        "envs/HTSeq_pandas_samtools_seaborn.yaml"
    log:
        os.path.join(config["local_log"],"count_sequences_{sample}.log")
    shell:
        "(python {input.script} \
        --bam {input.bam} \
        --out {params.outdir} \
        --verbose) &> {log}"


################################################################################
### merge count sequences
################################################################################

rule merge_count_sequences:
    input:
        counts = expand(os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered", "counts.tsv"), sample=get_samples())
    output:
        counts = os.path.join(config["output_dir"], "counts", "alignment.sorted.filtered", "counts.tsv")
    params:
        sample_name = expand("{sample}", sample=get_samples())
    threads:    1
    log:
        os.path.join(config["local_log"],"merge_count_sequences.log")
    run:
        dfs = []
        for i in range(0, len(input.counts)):
            df = pd.read_csv(input.counts[i], header=0, sep="\t")
            df["counts"] = df["counts"].round()
            sample_name = params.sample_name[i]
            df.columns = ["Name", sample_name]
            dfs.append(df)
        df_final = reduce(lambda left,right: pd.merge(left, right, on='Name', how="outer"), dfs)
        df_final.fillna(0, inplace=True)
        df_final.to_csv(output.counts, header=True, sep="\t", index=False)

################################################################################
################################################################################
### PART A: 22G RNAs after filtering
################################################################################
################################################################################


################################################################################
### subset 22G RNAs
################################################################################

rule subset_22G_RNAs:
    input:
        counts = os.path.join(config["output_dir"], "counts", "alignment.sorted.filtered", "counts.tsv")
    output:
        counts = os.path.join(config["output_dir"], "counts", "alignment.sorted.filtered", "counts.22G.tsv")
    log:
        os.path.join(config["local_log"],"subset_22G_RNAs.log")
    run:
        df = pd.read_csv(input.counts, header=0, sep="\t")
        df_subset = df[(df["Name"].str.startswith("G")) & (df["Name"].str.len() == 22)].copy()
        df_subset.to_csv(output.counts, header=True, sep="\t", index=False)

################################################################################
### split 22G RNAs counts
################################################################################

rule split_22G_RNAs_counts:
    input:
        counts = os.path.join(config["output_dir"], "counts", "alignment.sorted.filtered", "counts.22G.tsv")
    output:
        counts = os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered", "counts.22G.tsv")
    params:
        sample_name = "{sample}"
    log:
        os.path.join(config["local_log"],"split_22G_RNAs_counts_{sample}.log")
    run:
        df = pd.read_csv(input.counts, header=0, sep="\t")[["Name", params.sample_name]]
        df.columns = ["Name", "counts"]
        df.to_csv(output.counts, header=True, sep="\t", index=False)

################################################################################
### Input preparation for edgeR
################################################################################

rule edgeR_prepare_pairs_22G:
    input:
        counts1 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample1}", "counts", "alignment.sorted.filtered", "counts.22G.tsv"), sample1=config["experiment_samples"][wildcards.experiment1]),
        counts2 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample2}", "counts", "alignment.sorted.filtered", "counts.22G.tsv"), sample2=config["experiment_samples"][wildcards.experiment2]),
        script = os.path.join(config["scripts"], "edger_prepare_files.py")
    output:
        counts = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "prepare_pairs", "counts.table"),
        conditions = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "prepare_pairs", "conditions")
    params:
        output_dir = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "prepare_pairs"),
        condition1_name = "{experiment1}",
        condition2_name = "{experiment2}"
    log:
        os.path.join(config["local_log"], "edgeR_prepare_pairs_22G__{experiment1}__{experiment2}.log")
    threads:    1
	shell:
		"(mkdir -p {params.output_dir}; \
		python {input.script} \
		--input_condition1 '{input.counts1}' \
		--condition1_name {params.condition1_name} \
		--input_condition2 '{input.counts2}' \
		--condition2_name {params.condition2_name} \
		--outfile_counts {output.counts} \
		--outfile_conditions {output.conditions}) &> {log}"

################################################################################
### Differential expression between conditions
################################################################################

rule edgeR_differential_22G:
    input:
        counts = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "prepare_pairs", "counts.table"),
        conditions = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "prepare_pairs", "conditions"),
        script = os.path.join(config["scripts"], "DE_simple.R")
    output:
        table_FDR_low_tsv = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "final_table_FDR_low.tsv"),
        table_all = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "final_table.tsv")
    params:
        output_dir = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR"),
    conda:
        "envs/DE.yaml"
    log:
        os.path.join(config["local_log"], "edgeR_differential_22G__{experiment1}__{experiment2}.log")
    threads:    1
    shell:
        "(mkdir -p {params.output_dir}; \
        Rscript {input.script} \
        --conditions {input.conditions} \
        --counts {input.counts} \
        --outfolder {params.output_dir}) &> {log}"

################################################################################
### Select subset of 22G RNAs and extract the sequence
################################################################################

rule convert_subset_of_22G_RNAs_to_fasta:
    input:
        table_FDR_low_tsv = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "final_table_FDR_low.tsv"),
    output:
        fasta = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "22G_RNAs.fa")
    log:
        os.path.join(config["local_log"], "convert_subset_of_22G_RNAs_to_fasta__{experiment1}__{experiment2}.log")
    threads:    1
    run:
        df = pd.read_csv(input.table_FDR_low_tsv, header=0, sep="\t")
        df = df[df["logFC"]<0]
        with open(output.fasta, 'w') as w:
            for idx, row in df.iterrows():
                w.write(">"+row["id"]+os.linesep)
                w.write(row["id"]+os.linesep)

################################################################################
### bowtie align extracted subset
################################################################################

rule bowtie_align_extracted_subset:
    input:
        reads = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "22G_RNAs.fa"),
        bowtie_index = config["bowtie_index"]
    output:
        bam = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "alignment.sorted.bam"),
        bai = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "alignment.sorted.bam.bai"),
    params:
        index_prefix = config["bowtie_index"] + "/bowtie"
    threads:   8
    conda:
        "envs/bowtie.yaml"
    log:
        os.path.join(config["local_log"],"bowtie_align_extracted_subset__{experiment1}__{experiment2}.log")
    shell:
        "(bowtie \
        -v 0 \
        --all \
        --best \
        --strata \
        --sam \
        --fr \
        -f \
        --threads {threads} \
        {params.index_prefix} \
        {input.reads} \
        | samtools view -bS - \
        | samtools sort \
        -m 10G \
        --threads {threads} \
        --output-fmt BAM - \
        -o {output.bam}; \
        samtools index -@ {threads} {output.bam} {output.bai}; \
        ) &> {log}"

################################################################################
### HTSeq count genomic alignment
################################################################################

rule count_extracted_subset:
    input:
        bam = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "alignment.sorted.bam"),
        bai = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "alignment.sorted.bam.bai"), 
        gtf = config["gtf_canonical_and_transposon_transcripts"]
    output:
        htseq_counts_table = os.path.join(config["output_dir"], "comparisons", "DE__22G__{experiment1}__{experiment2}", "DE_edgeR", "counts22G.tsv"), 
    log:
        os.path.join(config["local_log"],"count_extrsacted_subset__{experiment1}__{experiment2}.log")
    threads:    1
    conda:
        "envs/HTSeq_pandas_samtools_seaborn.yaml"
    shell:
        "(htseq-count \
        --format bam \
        --stranded no \
        --type exon \
        --idattr gene_id \
        --mode union \
        --nonunique all \
        --secondary-alignments ignore \
        --supplementary-alignments ignore \
        {input.bam} \
        {input.gtf} > {output.htseq_counts_table}) 2> {log}"


################################################################################
################################################################################
### PART B: all RNAs after filtering
################################################################################
################################################################################

################################################################################
### split (all) RNAs counts
################################################################################

rule split_RNAs_counts:
    input:
        counts = os.path.join(config["output_dir"], "counts", "alignment.sorted.filtered", "counts.tsv")
    output:
        counts = os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered", "counts.all.tsv")
    params:
        sample_name = "{sample}"
    log:
        os.path.join(config["local_log"],"split_RNAs_counts_{sample}.log")
    run:
        df = pd.read_csv(input.counts, header=0, sep="\t")[["Name", params.sample_name]]
        df.columns = ["Name", "counts"]
        df.to_csv(output.counts, header=True, sep="\t", index=False)

################################################################################
### Input preparation for edgeR
################################################################################

rule edgeR_prepare_pairs_all:
    input:
        counts1 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample1}", "counts", "alignment.sorted.filtered", "counts.all.tsv"), sample1=config["experiment_samples"][wildcards.experiment1]),
        counts2 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample2}", "counts", "alignment.sorted.filtered", "counts.all.tsv"), sample2=config["experiment_samples"][wildcards.experiment2]),
        script = os.path.join(config["scripts"], "edger_prepare_files.py")
    output:
        counts = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "prepare_pairs", "counts.table"),
        conditions = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "prepare_pairs", "conditions")
    params:
        output_dir = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "prepare_pairs"),
        condition1_name = "{experiment1}",
        condition2_name = "{experiment2}"
    log:
        os.path.join(config["local_log"], "edgeR_prepare_pairs_all__{experiment1}__{experiment2}.log")
    threads:    1
	shell:
		"(mkdir -p {params.output_dir}; \
		python {input.script} \
		--input_condition1 '{input.counts1}' \
		--condition1_name {params.condition1_name} \
		--input_condition2 '{input.counts2}' \
		--condition2_name {params.condition2_name} \
		--outfile_counts {output.counts} \
		--outfile_conditions {output.conditions}) &> {log}"

################################################################################
### Differential expression between conditions
################################################################################

rule edgeR_differential_all:
    input:
        counts = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "prepare_pairs", "counts.table"),
        conditions = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "prepare_pairs", "conditions"),
        script = os.path.join(config["scripts"], "DE_simple.R")
    output:
        table_FDR_low_tsv = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "DE_edgeR", "final_table_FDR_low.tsv"),
        table_all = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "DE_edgeR", "final_table.tsv")
    params:
        output_dir = os.path.join(config["output_dir"], "comparisons", "DE__all__{experiment1}__{experiment2}", "DE_edgeR"),
    conda:
        "envs/DE.yaml"
    log:
        os.path.join(config["local_log"], "edgeR_differential_all__{experiment1}__{experiment2}.log")
    threads:    1
    shell:
        "(mkdir -p {params.output_dir}; \
        Rscript {input.script} \
        --conditions {input.conditions} \
        --counts {input.counts} \
        --outfolder {params.output_dir}) &> {log}"


# ################################################################################
# ### Extract gtf with miRNAs
# ################################################################################

# rule create_mirna_gtf:
#     input:
#         gtf = config["gtf"],
#     output:
#         gtf = os.path.join(config["output_dir"], "annotation", "mirnas.gtf")
#     log:
#         os.path.join(config["local_log"], "create_mirna_gtf.log")
#     shell:
#         "(grep -P 'transcript_biotype \"miRNA\"' {input.gtf} > {output.gtf}) &> {log}"

# ################################################################################
# ### Extract miRNA sequences
# ################################################################################

# rule extract_miRNA_sequences:
#     input:
#         gtf = os.path.join(config["output_dir"], "annotation", "mirnas.gtf"),
#         genome = config["genome"]
#     output:
#         seq = os.path.join(config["output_dir"], "annotation", "mirnas.fa")
#     conda:
#         "envs/cufflinks.yaml"
#     log:
#         os.path.join(config["local_log"], "extract_miRNA_sequences.log")
#     shell:
#         "(gffread \
#         {input.gtf} \
#         -g {input.genome} \
#         -w {output.seq} \
#         ) &> {log}"

# ################################################################################
# ### plot_small_RNAs
# ################################################################################

# rule plot_small_RNAs:
#     input:
#         table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR", "final_table.tsv"),
#         mirnas = os.path.join(config["output_dir"], "annotation", "mirnas.fa"),
#         script = os.path.join(config["scripts"], "plot_small_RNAs.py")
#     output:
#         out = directory(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "plot_small_RNAs"))
#     params:
#         comparison_name = "DE__{experiment1}__{experiment2}"
#     log:
#         os.path.join(config["local_log"], "plot_small_RNAs__{experiment1}__{experiment2}.log")
#     threads:    1
#     conda:
#         "envs/HTSeq_pandas_samtools_seaborn.yaml"
#     shell:
#         "(python {input.script} \
#         --DE_edgeR_table {input.table_all} \
#         --comparison_name {params.comparison_name} \
#         --mirnas {input.mirnas} \
#         --out {output.out} \
#         --verbose;) &> {log}"

# ################################################################################
# ### keep unique mappers
# ################################################################################

# rule samtools_keep_unique_mappers:
#     input:
#         bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam"),
#         bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.bam.bai")
#     output:
#         bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam"),
#         bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam.bai"),
#     threads:    1
#     conda:
#         "envs/samtools.yaml"
#     log:
#         os.path.join(config["local_log"],"samtools_keep_unique_mappers_{sample}.log")
#     shell:
#         "(cat \
#         <(samtools view -H {input.bam}) \
#         <(samtools view {input.bam} |  \
#         grep -P \"\tXM\:i\:2\$\")  | \
#         samtools view -bS - > {output.bam}; \
#         samtools index -@ {threads} {output.bam} {output.bai}; \
#         ) &> {log}"

# ################################################################################
# ### Determine alignment statistics unique mappers
# ################################################################################

# rule alfa_aligment_statistics_unique_mappers:
#     input:
#         bam = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam"), sample1=get_samples()),
#         bai = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam.bai"), sample1=get_samples()),
#         alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index")
#     output:
#         pdf = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_unique_mappers", "alfa_aligment_statistics_unique_mappers.Biotypes.pdf")
#     params:
#         genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index"),
#         output_prefix = "alfa_aligment_statistics_unique_mappers",
#         output_dir = os.path.abspath(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_unique_mappers")),
#         bam_and_sample_name = expand(str(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam ")) +str("{sample1}"), sample1=get_samples()),
#         strandness = "forward"
#     log:
#         os.path.join(config["local_log"],"alfa_aligment_statistics_unique_mappers.log")
#     threads:    20
#     conda:
#         "envs/alfa.yaml"
#     shell:
#         "(mkdir -p {params.output_dir}; \
#         alfa \
#         -g {params.genome_index_basename} \
#         --bam {params.bam_and_sample_name} \
#         -d 2 \
#         --keep_ambiguous \
#         --processors {threads} \
#         --strandness {params.strandness} \
#         --pdf {params.output_prefix} \
#         --temp_dir {params.output_dir} \
#         -o {params.output_dir}; \
#         ) &> {log}"

# ################################################################################
# ### count sequences unique mappers
# ################################################################################

# rule count_sequences_unique_mappers:
#     input:
#         bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam"),
#         bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam.bai"),
#         script = os.path.join(config["scripts"], "count_sequences.py")
#     output:
#         counts = os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered.unique_mappers", "counts.tsv")
#     params:
#         outdir = os.path.join(config["output_dir"], "{sample}", "counts", "alignment.sorted.filtered.unique_mappers")
#     threads:    1
#     conda:
#         "envs/HTSeq_pandas_samtools_seaborn.yaml"
#     log:
#         os.path.join(config["local_log"],"count_sequences_unique_mappers_{sample}.log")
#     shell:
#         "(python {input.script} \
#         --bam {input.bam} \
#         --out {params.outdir} \
#         --verbose) &> {log}"

# ################################################################################
# ### Input preparation for edgeR unique mappers
# ################################################################################

# rule edgeR_prepare_pairs_unique_mappers:
#     input:
#         counts1 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample1}", "counts", "alignment.sorted.filtered.unique_mappers", "counts.tsv"), sample1=config["experiment_samples"][wildcards.experiment1]),
#         counts2 = lambda wildcards: expand(os.path.join(config["output_dir"], "{sample2}", "counts", "alignment.sorted.filtered.unique_mappers", "counts.tsv"), sample2=config["experiment_samples"][wildcards.experiment2]),
#         script = os.path.join(config["scripts"], "edger_prepare_files.py")
#     output:
#         counts = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs_unique_mappers", "counts.table"),
#         conditions = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs_unique_mappers", "conditions")
#     params:
#         output_dir = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs_unique_mappers"),
#         condition1_name = "{experiment1}",
#         condition2_name = "{experiment2}"
#     log:
#         os.path.join(config["local_log"], "edgeR_prepare_pairs_unique_mappers_{experiment1}__{experiment2}.log")
#     threads:    1
# 	shell:
# 		"(mkdir -p {params.output_dir}; \
# 		python {input.script} \
# 		--input_condition1 '{input.counts1}' \
# 		--condition1_name {params.condition1_name} \
# 		--input_condition2 '{input.counts2}' \
# 		--condition2_name {params.condition2_name} \
# 		--outfile_counts {output.counts} \
# 		--outfile_conditions {output.conditions}) &> {log}"

# ################################################################################
# ### Differential expression between conditions unique mappers
# ################################################################################

# rule edgeR_differential_unique_mappers:
#     input:
#         counts = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs_unique_mappers", "counts.table"),
#         conditions = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "prepare_pairs_unique_mappers", "conditions"),
#         script = os.path.join(config["scripts"], "DE_simple.R")
#     output:
#         table_FDR_low_tsv = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR_unique_mappers", "final_table_FDR_low.tsv"),
#         table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR_unique_mappers", "final_table.tsv")
#     params:
#         output_dir = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR_unique_mappers"),
#         cluster_log = os.path.join(config["cluster_log"], "edgeR_differential__{experiment1}__{experiment2}.log")
#     conda:
#         "envs/DE.yaml"
#     log:
#         os.path.join(config["local_log"], "edgeR_differential_unique_mappers_{experiment1}__{experiment2}.log")
#     threads:    1
#     shell:
#         "(mkdir -p {params.output_dir}; \
#         Rscript {input.script} \
#         --conditions {input.conditions} \
#         --counts {input.counts} \
#         --outfolder {params.output_dir}) &> {log}"

# ################################################################################
# ### plot_small_RNAs unique mappers
# ################################################################################

# rule plot_small_RNAs_unique_mappers:
#     input:
#         table_all = os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "DE_edgeR_unique_mappers", "final_table.tsv"),
#         mirnas = os.path.join(config["output_dir"], "annotation", "mirnas.fa"),
#         script = os.path.join(config["scripts"], "plot_small_RNAs.py")
#     output:
#         out = directory(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "plot_small_RNAs_unique_mappers"))
#     params:
#         comparison_name = "DE_unique_mappers__{experiment1}__{experiment2}"
#     log:
#         os.path.join(config["local_log"], "plot_small_RNAs_unique_mappers_{experiment1}__{experiment2}.log")
#     threads:    1
#     conda:
#         "envs/HTSeq_pandas_samtools_seaborn.yaml"
#     shell:
#         "(python {input.script} \
#         --DE_edgeR_table {input.table_all} \
#         --comparison_name {params.comparison_name} \
#         --mirnas {input.mirnas} \
#         --out {output.out} \
#         --verbose;) &> {log}"

# ################################################################################
# ### Filter miRNAs in order to see on the general statistics RNAs that we are not interested in
# ### (miRNA)
# ################################################################################

# rule filter_miRNAs:
#     input:
#         bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam"),
#         bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.bam.bai"),
#         gtf = os.path.join(config["output_dir"], "annotation", "c_elegans.WS220.annotations.trs.exon.corrected_with_gene_id.gtf"),
#         script = os.path.join(config["scripts"], "filter_RNAs.py"),
#     output:
#         bam = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.filter_mirnas.bam"),
#         bai = os.path.join(config["output_dir"], "{sample}", "bowtie", "alignment.sorted.filtered.unique_mappers.filter_mirnas.bam.bai")
#     params:
#         filter_RNAs = "\"miRNA\"",
#         filter_chromosomes = "chrM"
#     log:
#         os.path.join(config["local_log"],"filter_miRNAs_{sample}.log")
#     threads:    2
#     conda:
#         "envs/HTSeq_pandas_samtools_seaborn.yaml"
#     shell:
#         "(python {input.script} \
#         --gtf {input.gtf} \
#         --bam {input.bam} \
#         --filter_RNAs {params.filter_RNAs} \
#         --filter_chromosomes {params.filter_chromosomes} \
#         --bam_out {output.bam} \
#         --verbose; \
#         samtools index -@ {threads} {output.bam} {output.bai};)"

# ################################################################################
# ### Determine alignment statistics unique mappers and filter miRNAs
# ################################################################################

# rule alfa_aligment_statistics_unique_mappers_filter_miRNAs:
#     input:
#         bam = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.unique_mappers.filter_mirnas.bam"), sample1=get_samples()),
#         bai = expand(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.unique_mappers.filter_mirnas.bam.bai"), sample1=get_samples()),
#         alfa_index_stranded = os.path.join(config["output_dir"], "annotation", "alfa_genome_index.stranded.ALFA_index")
#     output:
#         pdf = os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_unique_mappers_filter_miRNAs", "alfa_aligment_statistics_unique_mappers_filter_miRNAs.Biotypes.pdf")
#     params:
#         genome_index_basename = os.path.join(config["output_dir"], "annotation", "alfa_genome_index"),
#         output_prefix = "alfa_aligment_statistics_unique_mappers_filter_miRNAs",
#         output_dir = os.path.abspath(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_unique_mappers_filter_miRNAs")),
#         bam_and_sample_name = expand(str(os.path.join(config["output_dir"], "{sample1}", "bowtie", "alignment.sorted.filtered.unique_mappers.filter_mirnas.bam ")) +str("{sample1}"), sample1=get_samples()),
#         strandness = "forward"
#     log:
#         os.path.join(config["local_log"], "alfa_aligment_statistics_unique_mappers_filter_miRNAs.log")
#     threads:    20
#     conda:
#         "envs/alfa.yaml"
#     shell:
#         "(mkdir -p {params.output_dir}; \
#         alfa \
#         -g {params.genome_index_basename} \
#         --bam {params.bam_and_sample_name} \
#         -d 2 \
#         --keep_ambiguous \
#         --processors {threads} \
#         --strandness {params.strandness} \
#         --pdf {params.output_prefix} \
#         --temp_dir {params.output_dir} \
#         -o {params.output_dir}; \
#         ) &> {log}"

# ################################################################################
# ### Multiqc
# ################################################################################

# rule multiqc:
#     input:
#         pdf_alfa_aligment_statistics = expand(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics", "alfa_aligment_statistics.Biotypes.pdf"), sample=get_samples()),
#         pdf_alfa_aligment_statistics_filter = expand(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_filter", "alfa_aligment_statistics_filter.Biotypes.pdf"), sample=get_samples()),
#         pdf_alfa_aligment_statistics_unique_mappers = expand(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_unique_mappers", "alfa_aligment_statistics_unique_mappers.Biotypes.pdf"), sample=get_samples()),
#         pdf_alfa_aligment_statistics_unique_mappers_filter_miRNAs = expand(os.path.join(config["output_dir"], "plots", "alfa_aligment_statistics_unique_mappers_filter_miRNAs", "alfa_aligment_statistics_unique_mappers_filter_miRNAs.Biotypes.pdf"), sample=get_samples()),
#         fastqc = expand(os.path.join(config["output_dir"], "{sample}", "fastqc"), sample=get_samples()),
#         plot_small_RNAs = expand(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "plot_small_RNAs"),
#                                  zip,
#                                  experiment1 = [i[0]  for i in list(config["combinations"])],
#                                  experiment2 = [i[1]  for i in list(config["combinations"])]),
#         plot_small_RNAs_unique_mappers = expand(os.path.join(config["output_dir"], "DE__{experiment1}__{experiment2}", "plot_small_RNAs_unique_mappers"),
#                                  zip,
#                                  experiment1 = [i[0]  for i in list(config["combinations"])],
#                                  experiment2 = [i[1]  for i in list(config["combinations"])])
#     output:
#         multiqc_dir = directory(os.path.join(config["output_dir"], "summary", "qc"))
#     log:
#         os.path.join(config["local_log"], "multiqc_fastqc.log")
#     conda:
#         "envs/multiqc.yaml"
#     shell:
#         "(multiqc --outdir {output.multiqc_dir} results logs) &> {log}"
