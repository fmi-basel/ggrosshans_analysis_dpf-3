configfile: "config.yaml"

################################################################################
### python modules
################################################################################

import os
import sys
import pandas as pd

################################################################################
### Finish
################################################################################

rule finish:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap_and_ce_11_repeats.filtered.merged.sorted.gtf"),
        tsv = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.tsv"),
        star_index = expand(os.path.join(config["output_dir"], "indexes", "canonical_geneset", "STAR_index", "{sjdbOverhang}"), sjdbOverhang=config["sjdbOverhang"]),
        bowtie_index = os.path.join(config["output_dir"], "indexes", "genome", "bowtie"),
        seq = os.path.join(config["output_dir"], "annotation", "mirnas.fa")
        # bowtie_index_repeats_filtered = os.path.join(config["output_dir"], "indexes", "repeats_filtered", "bowtie"),
        # salmon_index_repeats_filtered = os.path.join(config["output_dir"], "indexes", "repeats_filtered", "salmon.idx"),
        # bowtie_index_repeats = os.path.join(config["output_dir"], "indexes", "repeats", "bowtie"),
        # salmon_index_repeats = os.path.join(config["output_dir"], "indexes", "repeats", "salmon.idx"),
        # repeat2repFamily = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.repeat2repFamily.tsv"),
        # repeat2repFamily_filtered = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.repeat2repFamily.tsv"),
        # bed_transposons_wormbase =  os.path.join(config["output_dir"], "annotation", "transposons.bed")

rule keep_exons_gtf_canonical_geneset_wormbase:
    input:
        gtf = config["gtf_canonical_geneset_wormbase"]
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.gtf")
    log:
        os.path.join(config["local_log"], "keep_exons_gtf_canonical_geneset_wormbase.log")
    shell:
        "(grep -P '\texon\t' {input.gtf} > {output.gtf}) &> {log}"

rule ucsc_repeats_fix_MtDNA:
    input:
        ucsc_repeats =  config["ucsc_repeats"],
    output:
        ucsc_repeats = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.tsv")
    log:
        os.path.join(config["local_log"], "ucsc_repeats_fix_MtDNA.log")
    shell:
        "(sed 's/\tchrM\t/\tchrMtDNA\t/' \
        {input.ucsc_repeats} \
        > {output.ucsc_repeats}) &> {log}"
 
rule ucsc_repeats_to_gtf_and_bed:
    input:
        ucsc_repeats = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.tsv"),
        script = os.path.join(config["scripts"], "ucsc_repeats_to_gtf_gff_bed.py")
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.gtf"),
        gff = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.gff"),
        bed = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.bed"),
    log:
        os.path.join(config["local_log"], "ucsc_repeats_to_gtf_and_bed.log")
    shell:
        "(python {input.script} \
        --ucsc_repeats {input.ucsc_repeats} \
        --gtf {output.gtf} \
        --gff {output.gff} \
        --bed {output.bed} \
        --filter-chr \
        --verbose) &> {log}"

rule filter_repeats_gtf:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.gtf")
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.gtf")
    log:
        os.path.join(config["local_log"], "filter_repeats_gtf.log")
    shell:
        "(grep -P -v 'repClass \"Simple_repeat\"|repClass \"Low_complexity\"|repClass \"rRNA\"\' \
         {input.gtf} > {output.gtf}) &> {log}"

rule filter_repeats_gff:
    input:
        gff = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.gff")
    output:
        gff = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.gff")
    log:
        os.path.join(config["local_log"], "filter_repeats_gff.log")
    shell:
        "(grep -P -v 'repClass=Simple_repeat|repClass=Low_complexity|repClass=rRNA\' \
         {input.gff} > {output.gff}) &> {log}"

rule filter_repeats_bed:
    input:
        bed = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.bed"),
    output:
        bed = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.bed"),
    log:
        os.path.join(config["local_log"], "filter_repeats_bed.log")
    shell:
        "(grep -P -v 'Simple_repeat|Low_complexity|rRNA' \
         {input.bed} > {output.bed}) &> {log}"

rule filtered_gtf_repeats_to_tsv:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.gtf"),
        script = os.path.join(config["scripts"], "gtf_repeats_to_tsv.py")
    output:
        tsv = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.tsv")
    log:
        os.path.join(config["local_log"],"filtered_gtf_repeats_to_tsv.log")
    threads:    1
    conda:
        os.path.join(config["envs"], "htseq_0.11.2_pandas_1.0.1_samtools_1.9_seaborn_0.9.yaml")
    shell:
        "(python {input.script} \
        --gtf {input.gtf} \
        --tsv {output.tsv} \
        --verbose \
        ) &> {log}"

rule keep_non_overlapping_exons_with_repeats:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.gtf"),
        bed = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.bed"),
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap.gtf")
    log:
        os.path.join(config["local_log"], "keep_non_overlapping_exons_with_repeats.log")
    conda:
        os.path.join(config["envs"], "bedtools_2.28.0.yaml")
    shell:
        "(bedtools intersect \
        -a {input.gtf} \
        -b {input.bed} \
        -s \
        -v \
        -wa \
        > {output.gtf}) &> {log}"

rule merge_canonical_annotation_non_overlapping_exons_and_repeats:
    input:
        gtf_canonical_no_repeat_overlap = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap.gtf"),
        gtf_repeats = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.gtf")
    output:
        gtf_canonical_and_repeats = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap_and_ce_11_repeats.filtered.merged.gtf"),
    log:
        os.path.join(config["local_log"], "merge_canonical_annotation_non_overlapping_exons_and_repeats.log")
    shell:
        "(cat \
        {input.gtf_canonical_no_repeat_overlap} \
        {input.gtf_repeats} \
        > {output.gtf_canonical_and_repeats}) &> {log}"

rule prepare_merged_annotation_for_igv:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap_and_ce_11_repeats.filtered.merged.gtf"), 
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap_and_ce_11_repeats.filtered.merged.sorted.gtf"),
        idx = os.path.join(config["output_dir"], "annotation", "canonical_geneset.exons.no_repeat_overlap_and_ce_11_repeats.filtered.merged.sorted.gtf.idx"),
    log:
        os.path.join(config["local_log"], "prepare_merged_annotation_for_igv.log")
    conda:
        os.path.join(config["envs"], "igvtools_2.3.93.yaml")
    shell:
        "(igvtools sort {input.gtf} {output.gtf}; \
        igvtools index {output.gtf};) &> {log}"


rule extract_repeat_sequences_filtered:
    input:
        annotation = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.gff"),
        genome = config["genome"]
    output:
        transcripts = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.fa")
    conda:
        os.path.join(config["envs"], "cufflinks_2.2.1.yaml")
    log:
        os.path.join(config["local_log"],"extract_repeat_sequences_filtered.log")
    shell:
        "(gffread {input.annotation} \
        -g {input.genome} \
        -w {output.transcripts}) &> {log}"

rule index_repeats_filtered_bowtie:
    input:
        transcripts = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.fa")
    output:
        index = directory(os.path.join(config["output_dir"], "indexes", "repeats_filtered", "bowtie"))
    params:
        prefix = os.path.join(config["output_dir"], "indexes", "repeats_filtered", "bowtie", "bowtie")
    threads:        20
    conda:
        os.path.join(config["envs"], "bowtie_1.2.3_samtools_1.9.yaml")
    log:
        os.path.join(config["local_log"],"index_repeats_filtered_bowtie.log")
    shell:
        "(mkdir -p {output.index}; \
        bowtie-build {input.transcripts} {params.prefix}) &> {log}"

rule index_repeats_filtered_salmon:
    input:
        transcripts = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.fa")
    output:
        index = directory(os.path.join(config["output_dir"], "indexes", "repeats_filtered", "salmon.idx"))
    params:
        kmer = 21
    threads:    20
    conda:
        os.path.join(config["envs"], "salmon_1.1.0.yaml")
    log:
        os.path.join(config["local_log"], "index_repeats_filtered_salmon.log")
    shell:
        "(salmon index \
        -t {input.transcripts} \
        -i {output.index} \
        -k {params.kmer}) &> {log}"

rule extract_repeat_sequences:
    input:
        annotation = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.gff"),
        genome = config["genome"]
    output:
        transcripts = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.fa")
    conda:
        os.path.join(config["envs"], "cufflinks_2.2.1.yaml")
    log:
        os.path.join(config["local_log"],"extract_repeat_sequences.log")
    shell:
        "(gffread {input.annotation} \
        -g {input.genome} \
        -w {output.transcripts}) &> {log}"

rule index_repeats_bowtie:
    input:
        transcripts = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.fa")
    output:
        index = directory(os.path.join(config["output_dir"], "indexes", "repeats", "bowtie"))
    params:
        prefix = os.path.join(config["output_dir"], "indexes", "repeats", "bowtie", "bowtie")
    threads:        20
    conda:
        os.path.join(config["envs"], "bowtie_1.2.3_samtools_1.9.yaml")
    log:
        os.path.join(config["local_log"],"index_repeats_bowtie.log")
    shell:
        "(mkdir -p {output.index}; \
        bowtie-build {input.transcripts} {params.prefix}) &> {log}"

rule index_repeats_salmon:
    input:
        transcripts = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.fa")
    output:
        index = directory(os.path.join(config["output_dir"], "indexes", "repeats", "salmon.idx"))
    params:
        kmer = 21
    threads:    20
    conda:
        os.path.join(config["envs"], "salmon_1.1.0.yaml")
    log:
        os.path.join(config["local_log"], "index_repeats_salmon.log")
    shell:
        "(salmon index \
        -t {input.transcripts} \
        -i {output.index} \
        -k {params.kmer}) &> {log}"

rule create_repeats_mappings:
    input:
        gff = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.gff")
    output:
        repeat2repName = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.repeat2repName.tsv"),
        repeat2repClass = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.repeat2repClass.tsv"),
        repeat2repFamily = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.repeat2repFamily.tsv")
    log:
        os.path.join(config["local_log"], "create_repeats_mappings.log")
    run:
        df = pd.read_csv(input.gff, header=None, sep="\t")
        df.columns = ["seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute"]
        df[["repeat", "repName", "repClass", "repFamily"]] = df["attribute"].str.split(";", n=3, expand=True)
        df["repFamily"] = df["repFamily"].str.replace(";","")
        df[["repeat", "repName"]].to_csv(output.repeat2repName, header=None, sep="\t", index=False)
        df[["repeat", "repClass"]].to_csv(output.repeat2repClass, header=None, sep="\t", index=False)
        df[["repeat", "repFamily"]].to_csv(output.repeat2repFamily, header=None, sep="\t", index=False)

rule create_repeats_filtered_mappings:
    input:
        gff = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.gff")
    output:
        repeat2repName = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.repeat2repName.tsv"),
        repeat2repClass = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.repeat2repClass.tsv"),
        repeat2repFamily = os.path.join(config["output_dir"], "annotation", "ce_11_repeats.filtered.repeat2repFamily.tsv")
    log:
        os.path.join(config["local_log"], "create_repeats_filtered_mappings.log")
    run:
        df = pd.read_csv(input.gff, header=None, sep="\t")
        df.columns = ["seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute"]
        df[["repeat", "repName", "repClass", "repFamily"]] = df["attribute"].str.split(";", n=3, expand=True)
        df["repFamily"] = df["repFamily"].str.replace(";","")
        df[["repeat", "repName"]].to_csv(output.repeat2repName, header=None, sep="\t", index=False)
        df[["repeat", "repClass"]].to_csv(output.repeat2repClass, header=None, sep="\t", index=False)
        df[["repeat", "repFamily"]].to_csv(output.repeat2repFamily, header=None, sep="\t", index=False)

rule index_genome_canonical_geneset_STAR:
    input:
        genome = config["genome"],
        annotation = config["gtf_canonical_geneset_wormbase"]
    output:
        outputdir = directory(os.path.join(config["output_dir"], "indexes", "canonical_geneset", "STAR_index", "{sjdbOverhang}"))
    params:
        sjdbOverhang = "{sjdbOverhang}",
        outputdir = os.path.join(config["output_dir"], "indexes", "canonical_geneset", "STAR_index"),
        tmpdir = os.path.join(config["output_dir"], "indexes", "canonical_geneset", "STAR_index", "tmp_{sjdbOverhang}"),
        outprefix = os.path.join(config["output_dir"], "indexes", "canonical_geneset", "STAR_index", "{sjdbOverhang}", "STAR_index_{sjdbOverhang}_"),
        genomeSAindexNbases = 12
    threads:    20
    conda:
        os.path.join(config["envs"], "STAR_2.7.0f.yaml")
    log:
        os.path.join(config["local_log"],"index_genome_canonical_geneset_STAR_{sjdbOverhang}.log")
    shell:
        "(mkdir -p {params.outputdir} {output.outputdir}; \
        chmod -R 777 {params.outputdir} {output.outputdir}; \
        STAR \
        --runMode genomeGenerate \
        --sjdbOverhang {params.sjdbOverhang} \
        --genomeDir {output.outputdir} \
        --outTmpDir {params.tmpdir} \
        --genomeFastaFiles {input.genome} \
        --genomeSAindexNbases {params.genomeSAindexNbases} \
        --outFileNamePrefix {params.outprefix} \
        --runThreadN {threads} \
        --sjdbGTFfile {input.annotation}) &> {log}"

rule index_genome_bowtie:
    input:
        genome = config["genome"],
    output:
        index = directory(os.path.join(config["output_dir"], "indexes", "genome", "bowtie"))
    params:
        prefix = os.path.join(config["output_dir"], "indexes", "genome", "bowtie", "bowtie")
    threads:    20
    conda:
        os.path.join(config["envs"], "bowtie_1.2.3_samtools_1.9.yaml")
    log:
        os.path.join(config["local_log"],"index_genome_bowtie.log")
    shell:
        "(mkdir -p {output.index}; \
        bowtie-build {input.genome} {params.prefix}) &> {log}"

rule gff_transposons_2_bed:
    input:
        gff_transposons_wormbase = config["gff_transposons_wormbase"]
    output:
        bed_transposons_wormbase =  os.path.join(config["output_dir"], "annotation", "transposons.bed")
    log:
        os.path.join(config["local_log"],"gff_transposons_2_bed.log")
    run:
        df = pd.read_csv(input.gff_transposons_wormbase, header=None, sep="\t")
        df.columns = ["chr", "db", "annotation", "start", "end", "n1", "strand", "n2", "id"]
        df["start"] = df["start"] - 1
        df = df[["chr", "start", "end", "id", "n1", "strand"]]
        df.to_csv(output.bed_transposons_wormbase, header=None, index=None, sep="\t")

rule create_mirna_gtf:
    input:
        gtf = config["gtf_canonical_geneset_wormbase"],
    output:
        gtf = os.path.join(config["output_dir"], "annotation", "mirnas.gtf")
    log:
        os.path.join(config["local_log"], "create_mirna_gtf.log")
    shell:
        "(grep -P 'transcript_biotype \"miRNA\"' {input.gtf} > {output.gtf}) &> {log}"

rule extract_miRNA_sequences:
    input:
        gtf = os.path.join(config["output_dir"], "annotation", "mirnas.gtf"),
        genome = config["genome"]
    output:
        seq = os.path.join(config["output_dir"], "annotation", "mirnas.fa")
    conda:
        os.path.join(config["envs"], "cufflinks_2.2.1.yaml")
    log:
        os.path.join(config["local_log"], "extract_miRNA_sequences.log")
    shell:
        "(gffread \
        {input.gtf} \
        -g {input.genome} \
        -w {output.seq} \
        ) &> {log}"

################################################################################
### Concatenate normal transcripts and transcripts annotated as
### transposons transcripts
### ALL (before filtering)
################################################################################

# rule concatenate_canonical_and_transposon_transcripts_all:
#     input:
#         gtf = config["gtf"],
#         gtf_transposon_transcripts = config["gtf_transposon_transcripts"]
#     output:
#         gtf = os.path.join(config["output_dir"], "annotation", "annotation.canonical_and_transposon_transcripts.gtf")
#     log:
#         os.path.join(config["local_log"], "concatenate_canonical_and_transposon_transcripts_all.log")
#     shell:
#         "(cat {input.gtf} {input.gtf_transposon_transcripts} > {output.gtf}) &> {log}"

# ################################################################################
# ### Filter small RNAs from annotation file
# ################################################################################

# rule filter_RNAs_from_gtf:
#     input:
#         gtf = config["gtf"]
#     output:
#         gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.gtf")
#     log:
#         os.path.join(config["local_log"], "filter_RNAs_from_gtf.log")
#     shell:
#         "(grep -P \"\texon\t\" {input.gtf} | \
#         grep -P -v \"miRNA|piRNA|pre_miRNA|rRNA|rRNA_pseudogene|snRNA|snoRNA|tRNA|tRNA_pseudogene\" | \
#         grep -P -v \"^MtDNA\" > {output.gtf}) &> {log}"

# ################################################################################
# ### Concatenate normal transcripts and transcripts annotated as
# ### transposons transcripts
# ################################################################################

# rule concatenate_canonical_and_transposon_transcripts:
#     input:
#         gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.gtf"),
#         gtf_transposon_transcripts = config["gtf_transposon_transcripts"]
#     output:
#         gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.gtf")
#     log:
#         os.path.join(config["local_log"], "concatenate_canonical_and_transposon_transcripts.log")
#     shell:
#         "(cat \
#         {input.gtf} \
#         <(grep -P \"\texon\t\" {input.gtf_transposon_transcripts}) \
#         > {output.gtf}) &> {log}"

# ################################################################################
# ### Extract canonical and transposon transcripts sequences
# ################################################################################

# rule extract_canonical_and_transposon_transcripts_sequences:
#     input:
#         gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.gtf"),
#         genome = config["genome"]
#     output:
#         seq = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.fa")
#     conda:
#         "envs/cufflinks.yaml"
#     log:
#         os.path.join(config["local_log"], "extract_canonical_and_transposon_transcripts_sequences.log")
#     shell:
#         "(gffread \
#         {input.gtf} \
#         -g {input.genome} \
#         -w {output.seq} \
#         ) &> {log}"

# ################################################################################
# ### Index canonical and transposon transcripts with salmon
# ################################################################################

# rule index_canonical_and_transposon_transcripts_salmon:
#     input:
#         transcripts = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.fa")
#     output:
#         index = directory(os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.salmon.idx"))
#     params:
#         kmer = 21
#     threads:    20
#     conda:
#         "envs/salmon.yaml"
#     log:
#         os.path.join(config["local_log"], "index_canonical_and_transposon_transcripts_salmon.log")
#     shell:
#         "(salmon index \
#         -t {input.transcripts} \
#         -i {output.index} \
#         -k {params.kmer}) &> {log}"

# ################################################################################
# ### canonical and transposon transcripts transcript id to gene id
# ################################################################################

# rule transcript_id_to_gene_id_canonical_and_transposon_transcripts:
#     input:
#         gtf = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.gtf"),
#     output:
#         transcriptid2geneid = os.path.join(config["output_dir"], "annotation", "annotation.filtered.canonical_and_transposon_transcripts.transcriptid2geneid.txt")
#     log:
#         os.path.join(config["local_log"], "transcript_id_to_gene_id_canonical_and_transposon_transcripts.log")
#     shell:
#         "(cut -f 9 {input.gtf} | \
#         cut -f 1-2 -d \";\" | \
#         sed \'s/gene_id \"//\' | \
#         sed \'s/\"; transcript_id \"/ /\' | \
#         sed \'s/\\\"//\' | \
#         sort -u | \
#         awk \'{{print $2 \" \" $1}}\' \
#         > {output.transcriptid2geneid} \
#         ) &> {log}"
